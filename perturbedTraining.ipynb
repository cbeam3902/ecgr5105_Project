{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Networks Survey - Training\n",
    "\n",
    "The models output are set to 1000 classes, because we are using the CIFAR 10 dataset we will need to train the network for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetModels = [\"alexnet\", \"googlenet\", \"mobilenet\"]\n",
    "\n",
    "datasetAlgorithm = [\"deepfool\", \"fgsm\", \"jsma\"]\n",
    "\n",
    "datasetAppend = [\"_train.pt\", \"_test.pt\"]\n",
    "\n",
    "stateDictNames = [\"alexnet_state_dict\", \"googlenet_state_dict\", \"mobilenet_state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Custom dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((70,70)),\n",
    "    transforms.RandomCrop((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "transformUnnormalize = transforms.Compose({\n",
    "    transforms.Normalize((0, 0, 0), (1/0.229, 1/0.224, 1/0.225)),\n",
    "    transforms.Normalize((-0.485, -0.456, -0.406), (1, 1, 1))\n",
    "})\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"models/models.pt\"):\n",
    "    raise FileNotFoundError(\"File 'models.pt' not found in folder models. Please run initialTraining.ipynb to generate the file needed! (File not included due to size)\")\n",
    "\n",
    "trained_weights_cifar10 = torch.load(\"models/models.pt\")\n",
    "\n",
    "modelNames = [\"alexnet\", \"googlenet\", \"mobilenet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, device=\"cpu\"):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alexnet Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.alexnet(weights=torchvision.models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "num_feats = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_feats, 10)\n",
    "nameIdx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepFool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(trained_weights_cifar10[stateDictNames[nameIdx]])\n",
    "algorithmIdx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"perturbedDataset/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+datasetAppend[0])\n",
    "perturbedImgCollection = checkpoint[\"perturbedImgCollection\"]\n",
    "perturbedImgCollection.requires_grad = False\n",
    "perturbedLabelCollection = checkpoint[\"perturbedLabelCollection\"]\n",
    "gtLabelCollection = checkpoint[\"gtLabelCollection\"]\n",
    "gtLabelCollection = gtLabelCollection.long()\n",
    "\n",
    "trainset = CustomDataset(perturbedImgCollection, gtLabelCollection, transform=None)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [8000, 2000])\n",
    "\n",
    "trainload = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valload = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {\"train\": trainload, \"val\": valload}\n",
    "dataset_sizes = {\"train\": len(trainset), \"val\": len(valset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.9043 Acc: 0.5092\n",
      "val Loss: 0.7756 Acc: 0.6415\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.7694 Acc: 0.6440\n",
      "val Loss: 0.6898 Acc: 0.7070\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.6460 Acc: 0.7284\n",
      "val Loss: 0.6196 Acc: 0.7645\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5686 Acc: 0.7780\n",
      "val Loss: 0.5687 Acc: 0.7865\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.5111 Acc: 0.8041\n",
      "val Loss: 0.5354 Acc: 0.8025\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4708 Acc: 0.8249\n",
      "val Loss: 0.5156 Acc: 0.8125\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.4276 Acc: 0.8425\n",
      "val Loss: 0.5017 Acc: 0.8195\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.4049 Acc: 0.8556\n",
      "val Loss: 0.5006 Acc: 0.8200\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.4036 Acc: 0.8585\n",
      "val Loss: 0.4994 Acc: 0.8195\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.4052 Acc: 0.8549\n",
      "val Loss: 0.4984 Acc: 0.8200\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.4014 Acc: 0.8560\n",
      "val Loss: 0.4973 Acc: 0.8195\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3972 Acc: 0.8546\n",
      "val Loss: 0.4962 Acc: 0.8200\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3925 Acc: 0.8578\n",
      "val Loss: 0.4952 Acc: 0.8205\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.3937 Acc: 0.8611\n",
      "val Loss: 0.4942 Acc: 0.8205\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3885 Acc: 0.8623\n",
      "val Loss: 0.4941 Acc: 0.8205\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3902 Acc: 0.8628\n",
      "val Loss: 0.4940 Acc: 0.8210\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.3883 Acc: 0.8615\n",
      "val Loss: 0.4939 Acc: 0.8215\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.3888 Acc: 0.8626\n",
      "val Loss: 0.4939 Acc: 0.8220\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.3870 Acc: 0.8654\n",
      "val Loss: 0.4938 Acc: 0.8220\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.3904 Acc: 0.8634\n",
      "val Loss: 0.4937 Acc: 0.8220\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.3898 Acc: 0.8640\n",
      "val Loss: 0.4936 Acc: 0.8220\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.3855 Acc: 0.8662\n",
      "val Loss: 0.4936 Acc: 0.8220\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.3858 Acc: 0.8625\n",
      "val Loss: 0.4936 Acc: 0.8220\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.3857 Acc: 0.8642\n",
      "val Loss: 0.4936 Acc: 0.8220\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3858 Acc: 0.8639\n",
      "val Loss: 0.4936 Acc: 0.8220\n",
      "\n",
      "Training complete in 0m 18s\n",
      "Best val Acc: 0.822000\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25, device=device)\n",
    "# alexnet = train_model(alexnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(trained_weights_cifar10[stateDictNames[nameIdx]])\n",
    "algorithmIdx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"perturbedDataset/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+datasetAppend[0])\n",
    "perturbedImgCollection = checkpoint[\"perturbedImgCollection\"]\n",
    "perturbedImgCollection.requires_grad = False\n",
    "perturbedLabelCollection = checkpoint[\"perturbedLabelCollection\"]\n",
    "gtLabelCollection = checkpoint[\"gtLabelCollection\"]\n",
    "gtLabelCollection = gtLabelCollection.long()\n",
    "\n",
    "trainset = CustomDataset(perturbedImgCollection, gtLabelCollection, transform=None)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [8000, 2000])\n",
    "\n",
    "trainload = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valload = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {\"train\": trainload, \"val\": valload}\n",
    "dataset_sizes = {\"train\": len(trainset), \"val\": len(valset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 1.2727 Acc: 0.6591\n",
      "val Loss: 1.0782 Acc: 0.6930\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.2132 Acc: 0.6655\n",
      "val Loss: 1.0268 Acc: 0.6990\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.1010 Acc: 0.6827\n",
      "val Loss: 0.9784 Acc: 0.7050\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.0140 Acc: 0.6913\n",
      "val Loss: 0.9360 Acc: 0.7100\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.9446 Acc: 0.7051\n",
      "val Loss: 0.8998 Acc: 0.7090\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.8785 Acc: 0.7206\n",
      "val Loss: 0.8741 Acc: 0.7110\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.8414 Acc: 0.7216\n",
      "val Loss: 0.8533 Acc: 0.7185\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.8049 Acc: 0.7281\n",
      "val Loss: 0.8517 Acc: 0.7185\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.8003 Acc: 0.7324\n",
      "val Loss: 0.8502 Acc: 0.7190\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.8035 Acc: 0.7291\n",
      "val Loss: 0.8488 Acc: 0.7190\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.8026 Acc: 0.7330\n",
      "val Loss: 0.8474 Acc: 0.7195\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.7923 Acc: 0.7374\n",
      "val Loss: 0.8461 Acc: 0.7205\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.7890 Acc: 0.7355\n",
      "val Loss: 0.8449 Acc: 0.7205\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.7871 Acc: 0.7368\n",
      "val Loss: 0.8437 Acc: 0.7205\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.7965 Acc: 0.7369\n",
      "val Loss: 0.8435 Acc: 0.7205\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.7830 Acc: 0.7369\n",
      "val Loss: 0.8434 Acc: 0.7205\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.7846 Acc: 0.7366\n",
      "val Loss: 0.8432 Acc: 0.7205\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.7905 Acc: 0.7378\n",
      "val Loss: 0.8431 Acc: 0.7205\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.7890 Acc: 0.7369\n",
      "val Loss: 0.8430 Acc: 0.7205\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.7861 Acc: 0.7385\n",
      "val Loss: 0.8429 Acc: 0.7205\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.7841 Acc: 0.7366\n",
      "val Loss: 0.8428 Acc: 0.7205\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.7890 Acc: 0.7389\n",
      "val Loss: 0.8427 Acc: 0.7205\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.7886 Acc: 0.7374\n",
      "val Loss: 0.8427 Acc: 0.7205\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.7889 Acc: 0.7382\n",
      "val Loss: 0.8427 Acc: 0.7205\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.7890 Acc: 0.7388\n",
      "val Loss: 0.8427 Acc: 0.7205\n",
      "\n",
      "Training complete in 0m 17s\n",
      "Best val Acc: 0.720500\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25, device=device)\n",
    "# alexnet = train_model(alexnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(trained_weights_cifar10[stateDictNames[nameIdx]])\n",
    "algorithmIdx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"perturbedDataset/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+datasetAppend[0])\n",
    "perturbedImgCollection = checkpoint[\"perturbedImgCollection\"]\n",
    "perturbedImgCollection.requires_grad = False\n",
    "perturbedLabelCollection = checkpoint[\"perturbedLabelCollection\"]\n",
    "gtLabelCollection = checkpoint[\"gtLabelCollection\"]\n",
    "gtLabelCollection = gtLabelCollection.long()\n",
    "\n",
    "trainset = CustomDataset(perturbedImgCollection, gtLabelCollection, transform=None)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [8000, 2000])\n",
    "\n",
    "trainload = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valload = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {\"train\": trainload, \"val\": valload}\n",
    "dataset_sizes = {\"train\": len(trainset), \"val\": len(valset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.2431 Acc: 0.9319\n",
      "val Loss: 0.2416 Acc: 0.9295\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.2410 Acc: 0.9351\n",
      "val Loss: 0.2405 Acc: 0.9300\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.2312 Acc: 0.9356\n",
      "val Loss: 0.2396 Acc: 0.9305\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.2177 Acc: 0.9365\n",
      "val Loss: 0.2392 Acc: 0.9305\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2093 Acc: 0.9400\n",
      "val Loss: 0.2392 Acc: 0.9310\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2053 Acc: 0.9393\n",
      "val Loss: 0.2391 Acc: 0.9310\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1936 Acc: 0.9454\n",
      "val Loss: 0.2389 Acc: 0.9315\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1898 Acc: 0.9435\n",
      "val Loss: 0.2389 Acc: 0.9310\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1925 Acc: 0.9427\n",
      "val Loss: 0.2388 Acc: 0.9315\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1890 Acc: 0.9434\n",
      "val Loss: 0.2388 Acc: 0.9310\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1896 Acc: 0.9460\n",
      "val Loss: 0.2388 Acc: 0.9305\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1904 Acc: 0.9451\n",
      "val Loss: 0.2387 Acc: 0.9310\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1886 Acc: 0.9460\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1881 Acc: 0.9443\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1896 Acc: 0.9437\n",
      "val Loss: 0.2387 Acc: 0.9310\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1892 Acc: 0.9441\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1864 Acc: 0.9441\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1859 Acc: 0.9469\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1873 Acc: 0.9434\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1888 Acc: 0.9454\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1866 Acc: 0.9437\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1879 Acc: 0.9441\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9426\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1862 Acc: 0.9450\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1892 Acc: 0.9431\n",
      "val Loss: 0.2387 Acc: 0.9305\n",
      "\n",
      "Training complete in 0m 17s\n",
      "Best val Acc: 0.931500\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25, device=device)\n",
    "# alexnet = train_model(alexnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.googlenet(weights=torchvision.models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "num_feats = model.fc.in_features\n",
    "model.fc = nn.Linear(num_feats, 10)\n",
    "nameIdx = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepFool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(trained_weights_cifar10[stateDictNames[nameIdx]])\n",
    "algorithmIdx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"perturbedDataset/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+datasetAppend[0])\n",
    "perturbedImgCollection = checkpoint[\"perturbedImgCollection\"]\n",
    "perturbedImgCollection.requires_grad = False\n",
    "perturbedLabelCollection = checkpoint[\"perturbedLabelCollection\"]\n",
    "gtLabelCollection = checkpoint[\"gtLabelCollection\"]\n",
    "gtLabelCollection = gtLabelCollection.long()\n",
    "\n",
    "trainset = CustomDataset(perturbedImgCollection, gtLabelCollection, transform=None)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [8000, 2000])\n",
    "\n",
    "trainload = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valload = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {\"train\": trainload, \"val\": valload}\n",
    "dataset_sizes = {\"train\": len(trainset), \"val\": len(valset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6989 Acc: 0.6710\n",
      "val Loss: 0.6587 Acc: 0.7520\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5819 Acc: 0.7590\n",
      "val Loss: 0.5345 Acc: 0.8030\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4782 Acc: 0.8261\n",
      "val Loss: 0.4333 Acc: 0.8565\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3920 Acc: 0.8731\n",
      "val Loss: 0.3601 Acc: 0.8880\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3360 Acc: 0.9038\n",
      "val Loss: 0.3193 Acc: 0.9045\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3035 Acc: 0.9111\n",
      "val Loss: 0.2958 Acc: 0.9125\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2819 Acc: 0.9201\n",
      "val Loss: 0.2801 Acc: 0.9170\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2691 Acc: 0.9273\n",
      "val Loss: 0.2760 Acc: 0.9190\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2679 Acc: 0.9261\n",
      "val Loss: 0.2739 Acc: 0.9205\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.2653 Acc: 0.9274\n",
      "val Loss: 0.2726 Acc: 0.9220\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.2648 Acc: 0.9303\n",
      "val Loss: 0.2717 Acc: 0.9225\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.2645 Acc: 0.9303\n",
      "val Loss: 0.2707 Acc: 0.9230\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.2615 Acc: 0.9280\n",
      "val Loss: 0.2699 Acc: 0.9235\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2606 Acc: 0.9320\n",
      "val Loss: 0.2692 Acc: 0.9230\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2610 Acc: 0.9276\n",
      "val Loss: 0.2691 Acc: 0.9225\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2614 Acc: 0.9280\n",
      "val Loss: 0.2687 Acc: 0.9235\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2612 Acc: 0.9275\n",
      "val Loss: 0.2688 Acc: 0.9230\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2580 Acc: 0.9319\n",
      "val Loss: 0.2688 Acc: 0.9230\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2591 Acc: 0.9321\n",
      "val Loss: 0.2688 Acc: 0.9230\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2598 Acc: 0.9290\n",
      "val Loss: 0.2688 Acc: 0.9230\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2595 Acc: 0.9276\n",
      "val Loss: 0.2686 Acc: 0.9225\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2595 Acc: 0.9309\n",
      "val Loss: 0.2686 Acc: 0.9230\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2602 Acc: 0.9283\n",
      "val Loss: 0.2684 Acc: 0.9230\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2587 Acc: 0.9295\n",
      "val Loss: 0.2687 Acc: 0.9230\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2595 Acc: 0.9303\n",
      "val Loss: 0.2687 Acc: 0.9235\n",
      "\n",
      "Training complete in 0m 36s\n",
      "Best val Acc: 0.923500\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25, device=device)\n",
    "# alexnet = train_model(alexnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(trained_weights_cifar10[stateDictNames[nameIdx]])\n",
    "algorithmIdx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"perturbedDataset/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+datasetAppend[0])\n",
    "perturbedImgCollection = checkpoint[\"perturbedImgCollection\"]\n",
    "perturbedImgCollection.requires_grad = False\n",
    "perturbedLabelCollection = checkpoint[\"perturbedLabelCollection\"]\n",
    "gtLabelCollection = checkpoint[\"gtLabelCollection\"]\n",
    "gtLabelCollection = gtLabelCollection.long()\n",
    "\n",
    "trainset = CustomDataset(perturbedImgCollection, gtLabelCollection, transform=None)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [8000, 2000])\n",
    "\n",
    "trainload = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valload = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {\"train\": trainload, \"val\": valload}\n",
    "dataset_sizes = {\"train\": len(trainset), \"val\": len(valset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 1.5355 Acc: 0.5773\n",
      "val Loss: 1.4592 Acc: 0.5745\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.4175 Acc: 0.5968\n",
      "val Loss: 1.3673 Acc: 0.6065\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.2659 Acc: 0.6304\n",
      "val Loss: 1.2373 Acc: 0.6370\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.1063 Acc: 0.6558\n",
      "val Loss: 1.0894 Acc: 0.6710\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.9582 Acc: 0.6960\n",
      "val Loss: 0.9508 Acc: 0.6965\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.8296 Acc: 0.7251\n",
      "val Loss: 0.8503 Acc: 0.7195\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.7419 Acc: 0.7474\n",
      "val Loss: 0.7857 Acc: 0.7290\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.6997 Acc: 0.7602\n",
      "val Loss: 0.7617 Acc: 0.7375\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.6979 Acc: 0.7625\n",
      "val Loss: 0.7514 Acc: 0.7420\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.6948 Acc: 0.7625\n",
      "val Loss: 0.7456 Acc: 0.7415\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.6902 Acc: 0.7611\n",
      "val Loss: 0.7411 Acc: 0.7440\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.6888 Acc: 0.7644\n",
      "val Loss: 0.7375 Acc: 0.7440\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 0.7651\n",
      "val Loss: 0.7346 Acc: 0.7455\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.6833 Acc: 0.7639\n",
      "val Loss: 0.7315 Acc: 0.7465\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.6731 Acc: 0.7695\n",
      "val Loss: 0.7307 Acc: 0.7475\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.6785 Acc: 0.7646\n",
      "val Loss: 0.7299 Acc: 0.7470\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.6737 Acc: 0.7705\n",
      "val Loss: 0.7293 Acc: 0.7465\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.6741 Acc: 0.7639\n",
      "val Loss: 0.7287 Acc: 0.7475\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.6749 Acc: 0.7664\n",
      "val Loss: 0.7287 Acc: 0.7480\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.6757 Acc: 0.7680\n",
      "val Loss: 0.7286 Acc: 0.7470\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.6751 Acc: 0.7648\n",
      "val Loss: 0.7283 Acc: 0.7475\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.7664\n",
      "val Loss: 0.7282 Acc: 0.7475\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.6753 Acc: 0.7684\n",
      "val Loss: 0.7281 Acc: 0.7470\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.6696 Acc: 0.7720\n",
      "val Loss: 0.7285 Acc: 0.7470\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.6714 Acc: 0.7682\n",
      "val Loss: 0.7285 Acc: 0.7470\n",
      "\n",
      "Training complete in 0m 38s\n",
      "Best val Acc: 0.748000\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25, device=device)\n",
    "# alexnet = train_model(alexnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(trained_weights_cifar10[stateDictNames[nameIdx]])\n",
    "algorithmIdx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"perturbedDataset/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+datasetAppend[0])\n",
    "perturbedImgCollection = checkpoint[\"perturbedImgCollection\"]\n",
    "perturbedImgCollection.requires_grad = False\n",
    "perturbedLabelCollection = checkpoint[\"perturbedLabelCollection\"]\n",
    "gtLabelCollection = checkpoint[\"gtLabelCollection\"]\n",
    "gtLabelCollection = gtLabelCollection.long()\n",
    "\n",
    "trainset = CustomDataset(perturbedImgCollection, gtLabelCollection, transform=None)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [8000, 2000])\n",
    "\n",
    "trainload = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valload = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {\"train\": trainload, \"val\": valload}\n",
    "dataset_sizes = {\"train\": len(trainset), \"val\": len(valset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.1711 Acc: 0.9560\n",
      "val Loss: 0.1677 Acc: 0.9545\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.1707 Acc: 0.9571\n",
      "val Loss: 0.1702 Acc: 0.9560\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.1642 Acc: 0.9596\n",
      "val Loss: 0.1699 Acc: 0.9565\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.1613 Acc: 0.9604\n",
      "val Loss: 0.1686 Acc: 0.9555\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1580 Acc: 0.9607\n",
      "val Loss: 0.1668 Acc: 0.9560\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1546 Acc: 0.9620\n",
      "val Loss: 0.1649 Acc: 0.9560\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1511 Acc: 0.9623\n",
      "val Loss: 0.1633 Acc: 0.9550\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9629\n",
      "val Loss: 0.1624 Acc: 0.9550\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1490 Acc: 0.9635\n",
      "val Loss: 0.1620 Acc: 0.9550\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1484 Acc: 0.9627\n",
      "val Loss: 0.1618 Acc: 0.9550\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1478 Acc: 0.9639\n",
      "val Loss: 0.1616 Acc: 0.9550\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1470 Acc: 0.9639\n",
      "val Loss: 0.1614 Acc: 0.9550\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1479 Acc: 0.9641\n",
      "val Loss: 0.1614 Acc: 0.9550\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1475 Acc: 0.9629\n",
      "val Loss: 0.1615 Acc: 0.9550\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1470 Acc: 0.9646\n",
      "val Loss: 0.1615 Acc: 0.9550\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1477 Acc: 0.9639\n",
      "val Loss: 0.1613 Acc: 0.9550\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1469 Acc: 0.9635\n",
      "val Loss: 0.1613 Acc: 0.9555\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1464 Acc: 0.9633\n",
      "val Loss: 0.1611 Acc: 0.9550\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1467 Acc: 0.9645\n",
      "val Loss: 0.1612 Acc: 0.9555\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1465 Acc: 0.9630\n",
      "val Loss: 0.1610 Acc: 0.9555\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1468 Acc: 0.9629\n",
      "val Loss: 0.1611 Acc: 0.9555\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1462 Acc: 0.9615\n",
      "val Loss: 0.1611 Acc: 0.9560\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1457 Acc: 0.9631\n",
      "val Loss: 0.1611 Acc: 0.9555\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9641\n",
      "val Loss: 0.1611 Acc: 0.9550\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1465 Acc: 0.9627\n",
      "val Loss: 0.1610 Acc: 0.9550\n",
      "\n",
      "Training complete in 0m 36s\n",
      "Best val Acc: 0.956500\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25, device=device)\n",
    "# alexnet = train_model(alexnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet V3 Large Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.mobilenet_v3_large(weights=torchvision.models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
    "num_feat = model.classifier[3].in_features\n",
    "model.classifier[3] = nn.Linear(num_feat, 10)\n",
    "nameIdx = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepFool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(trained_weights_cifar10[stateDictNames[nameIdx]])\n",
    "algorithmIdx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"perturbedDataset/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+datasetAppend[0])\n",
    "perturbedImgCollection = checkpoint[\"perturbedImgCollection\"]\n",
    "perturbedImgCollection.requires_grad = False\n",
    "perturbedLabelCollection = checkpoint[\"perturbedLabelCollection\"]\n",
    "gtLabelCollection = checkpoint[\"gtLabelCollection\"]\n",
    "gtLabelCollection = gtLabelCollection.long()\n",
    "\n",
    "trainset = CustomDataset(perturbedImgCollection, gtLabelCollection, transform=None)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [8000, 2000])\n",
    "\n",
    "trainload = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valload = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {\"train\": trainload, \"val\": valload}\n",
    "dataset_sizes = {\"train\": len(trainset), \"val\": len(valset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7457 Acc: 0.6204\n",
      "val Loss: 0.6684 Acc: 0.8510\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5840 Acc: 0.7394\n",
      "val Loss: 0.5016 Acc: 0.8725\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4385 Acc: 0.8354\n",
      "val Loss: 0.3972 Acc: 0.8935\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3498 Acc: 0.8820\n",
      "val Loss: 0.3465 Acc: 0.8950\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3027 Acc: 0.9059\n",
      "val Loss: 0.3224 Acc: 0.8970\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2751 Acc: 0.9134\n",
      "val Loss: 0.3097 Acc: 0.8985\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2595 Acc: 0.9175\n",
      "val Loss: 0.3015 Acc: 0.9005\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2504 Acc: 0.9246\n",
      "val Loss: 0.2977 Acc: 0.9020\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2463 Acc: 0.9258\n",
      "val Loss: 0.2943 Acc: 0.9025\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.2497 Acc: 0.9203\n",
      "val Loss: 0.2914 Acc: 0.9035\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.2476 Acc: 0.9215\n",
      "val Loss: 0.2890 Acc: 0.9055\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.2464 Acc: 0.9218\n",
      "val Loss: 0.2868 Acc: 0.9090\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.2433 Acc: 0.9253\n",
      "val Loss: 0.2850 Acc: 0.9085\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.2444 Acc: 0.9250\n",
      "val Loss: 0.2833 Acc: 0.9095\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.2447 Acc: 0.9236\n",
      "val Loss: 0.2821 Acc: 0.9110\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.2436 Acc: 0.9245\n",
      "val Loss: 0.2811 Acc: 0.9120\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.2424 Acc: 0.9233\n",
      "val Loss: 0.2803 Acc: 0.9115\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.2431 Acc: 0.9246\n",
      "val Loss: 0.2795 Acc: 0.9125\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.2449 Acc: 0.9235\n",
      "val Loss: 0.2787 Acc: 0.9130\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.2442 Acc: 0.9224\n",
      "val Loss: 0.2781 Acc: 0.9150\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.2431 Acc: 0.9224\n",
      "val Loss: 0.2776 Acc: 0.9150\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.2428 Acc: 0.9235\n",
      "val Loss: 0.2772 Acc: 0.9150\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.2436 Acc: 0.9234\n",
      "val Loss: 0.2769 Acc: 0.9165\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.2376 Acc: 0.9268\n",
      "val Loss: 0.2765 Acc: 0.9175\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.2424 Acc: 0.9268\n",
      "val Loss: 0.2763 Acc: 0.9170\n",
      "\n",
      "Training complete in 0m 29s\n",
      "Best val Acc: 0.917500\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25, device=device)\n",
    "# alexnet = train_model(alexnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(trained_weights_cifar10[stateDictNames[nameIdx]])\n",
    "algorithmIdx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"perturbedDataset/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+datasetAppend[0])\n",
    "perturbedImgCollection = checkpoint[\"perturbedImgCollection\"]\n",
    "perturbedImgCollection.requires_grad = False\n",
    "perturbedLabelCollection = checkpoint[\"perturbedLabelCollection\"]\n",
    "gtLabelCollection = checkpoint[\"gtLabelCollection\"]\n",
    "gtLabelCollection = gtLabelCollection.long()\n",
    "\n",
    "trainset = CustomDataset(perturbedImgCollection, gtLabelCollection, transform=None)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [8000, 2000])\n",
    "\n",
    "trainload = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valload = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {\"train\": trainload, \"val\": valload}\n",
    "dataset_sizes = {\"train\": len(trainset), \"val\": len(valset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 3.5574 Acc: 0.2680\n",
      "val Loss: 2.8919 Acc: 0.3195\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 3.0524 Acc: 0.3201\n",
      "val Loss: 2.4875 Acc: 0.3770\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 2.4753 Acc: 0.3914\n",
      "val Loss: 2.0690 Acc: 0.4385\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 2.0193 Acc: 0.4617\n",
      "val Loss: 1.7069 Acc: 0.5095\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.6743 Acc: 0.5182\n",
      "val Loss: 1.4260 Acc: 0.5755\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.4118 Acc: 0.5711\n",
      "val Loss: 1.2262 Acc: 0.6180\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.2280 Acc: 0.6119\n",
      "val Loss: 1.0898 Acc: 0.6530\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 1.1309 Acc: 0.6386\n",
      "val Loss: 1.0864 Acc: 0.6550\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 1.1188 Acc: 0.6382\n",
      "val Loss: 1.0835 Acc: 0.6550\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 1.1077 Acc: 0.6414\n",
      "val Loss: 1.0805 Acc: 0.6570\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 1.0957 Acc: 0.6466\n",
      "val Loss: 1.0774 Acc: 0.6555\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 1.0889 Acc: 0.6458\n",
      "val Loss: 1.0741 Acc: 0.6560\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 1.0751 Acc: 0.6522\n",
      "val Loss: 1.0707 Acc: 0.6570\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 1.0706 Acc: 0.6528\n",
      "val Loss: 1.0671 Acc: 0.6575\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 1.0625 Acc: 0.6539\n",
      "val Loss: 1.0724 Acc: 0.6540\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 1.0619 Acc: 0.6526\n",
      "val Loss: 1.0775 Acc: 0.6510\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 1.0611 Acc: 0.6536\n",
      "val Loss: 1.0824 Acc: 0.6490\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 1.0604 Acc: 0.6545\n",
      "val Loss: 1.0870 Acc: 0.6515\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 1.0619 Acc: 0.6521\n",
      "val Loss: 1.0914 Acc: 0.6510\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 1.0623 Acc: 0.6579\n",
      "val Loss: 1.0951 Acc: 0.6495\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 1.0567 Acc: 0.6559\n",
      "val Loss: 1.0985 Acc: 0.6500\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 1.0578 Acc: 0.6538\n",
      "val Loss: 1.1026 Acc: 0.6485\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 1.0574 Acc: 0.6555\n",
      "val Loss: 1.1062 Acc: 0.6495\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 1.0540 Acc: 0.6581\n",
      "val Loss: 1.1094 Acc: 0.6495\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 1.0574 Acc: 0.6562\n",
      "val Loss: 1.1123 Acc: 0.6500\n",
      "\n",
      "Training complete in 0m 29s\n",
      "Best val Acc: 0.657500\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25, device=device)\n",
    "# alexnet = train_model(alexnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(trained_weights_cifar10[stateDictNames[nameIdx]])\n",
    "algorithmIdx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"perturbedDataset/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+datasetAppend[0])\n",
    "perturbedImgCollection = checkpoint[\"perturbedImgCollection\"]\n",
    "perturbedImgCollection.requires_grad = False\n",
    "perturbedLabelCollection = checkpoint[\"perturbedLabelCollection\"]\n",
    "gtLabelCollection = checkpoint[\"gtLabelCollection\"]\n",
    "gtLabelCollection = gtLabelCollection.long()\n",
    "\n",
    "trainset = CustomDataset(perturbedImgCollection, gtLabelCollection, transform=None)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [8000, 2000])\n",
    "\n",
    "trainload = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valload = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = {\"train\": trainload, \"val\": valload}\n",
    "dataset_sizes = {\"train\": len(trainset), \"val\": len(valset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.1918 Acc: 0.9345\n",
      "val Loss: 0.1638 Acc: 0.9455\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.1881 Acc: 0.9360\n",
      "val Loss: 0.1616 Acc: 0.9460\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.1863 Acc: 0.9393\n",
      "val Loss: 0.1595 Acc: 0.9490\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.1836 Acc: 0.9406\n",
      "val Loss: 0.1578 Acc: 0.9500\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.1774 Acc: 0.9414\n",
      "val Loss: 0.1563 Acc: 0.9505\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.1766 Acc: 0.9403\n",
      "val Loss: 0.1551 Acc: 0.9510\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1715 Acc: 0.9434\n",
      "val Loss: 0.1540 Acc: 0.9525\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1708 Acc: 0.9425\n",
      "val Loss: 0.1536 Acc: 0.9535\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1699 Acc: 0.9437\n",
      "val Loss: 0.1533 Acc: 0.9540\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1725 Acc: 0.9407\n",
      "val Loss: 0.1530 Acc: 0.9535\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1686 Acc: 0.9434\n",
      "val Loss: 0.1527 Acc: 0.9530\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.1696 Acc: 0.9433\n",
      "val Loss: 0.1526 Acc: 0.9535\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1647 Acc: 0.9449\n",
      "val Loss: 0.1524 Acc: 0.9535\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1681 Acc: 0.9439\n",
      "val Loss: 0.1522 Acc: 0.9545\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1668 Acc: 0.9433\n",
      "val Loss: 0.1521 Acc: 0.9545\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1699 Acc: 0.9419\n",
      "val Loss: 0.1520 Acc: 0.9545\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.1681 Acc: 0.9434\n",
      "val Loss: 0.1520 Acc: 0.9560\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.1684 Acc: 0.9429\n",
      "val Loss: 0.1519 Acc: 0.9555\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.1684 Acc: 0.9434\n",
      "val Loss: 0.1519 Acc: 0.9555\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.1696 Acc: 0.9445\n",
      "val Loss: 0.1519 Acc: 0.9555\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.1708 Acc: 0.9427\n",
      "val Loss: 0.1518 Acc: 0.9550\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.1688 Acc: 0.9423\n",
      "val Loss: 0.1519 Acc: 0.9545\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.1685 Acc: 0.9433\n",
      "val Loss: 0.1518 Acc: 0.9545\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.1687 Acc: 0.9446\n",
      "val Loss: 0.1518 Acc: 0.9545\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.1672 Acc: 0.9450\n",
      "val Loss: 0.1518 Acc: 0.9545\n",
      "\n",
      "Training complete in 0m 29s\n",
      "Best val Acc: 0.956000\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25, device=device)\n",
    "# alexnet = train_model(alexnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/\"+datasetModels[nameIdx]+\"_\"+datasetAlgorithm[algorithmIdx]+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
